{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce83ddb3-76a0-4ba7-93ef-c2a21b48cfb6",
   "metadata": {},
   "source": [
    "# Overfitting\n",
    "\n",
    "**Note :** to use this notebook in Google Colab, create a new cell with\n",
    "the following line and run it.\n",
    "\n",
    "``` shell\n",
    "!pip install git+https://gitlab.in2p3.fr/jbarnier/ateliers_deep_learning.git\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import plotnine as pn\n",
    "import polars as pl\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchinfo import summary\n",
    "\n",
    "from adl import cooking\n",
    "\n",
    "pn.theme_set(pn.theme_minimal())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6043dd08-1dea-4ff7-b4ab-8d26bfd75467",
   "metadata": {},
   "source": [
    "In this notebook we will try to understand the concept of overfitting\n",
    "and why it can be problematic.\n",
    "\n",
    "To illustrate this concept we an example dataset, imagine that we are\n",
    "having some people taste and evaluate a cake recipe, by varying the cake\n",
    "cooking time from 5 to 120 minutes.\n",
    "\n",
    "Here is a sample generated dataset of 30 ratings based on the cooking\n",
    "time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random data\n",
    "np.random.seed(42)\n",
    "time, score = cooking.generate_data(size=30)\n",
    "# Add some outliers\n",
    "score[[2, 15, 26]] = torch.tensor([[9], [4], [8.5]])\n",
    "\n",
    "# Plot data\n",
    "cooking.scatter_plot(time, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563cb98f-1d00-4aae-96ee-842d025f2d73",
   "metadata": {},
   "source": [
    "In this plot, each dot represents a score associated to a cooking time.\n",
    "We can see that globally the data seems to follow a parabolic\n",
    "distribution, but that there are 3 outliers (introduced on purpose).\n",
    "\n",
    "We will train a dense neural network on this small dataset to try to\n",
    "predict the score from the cooking time value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(in_features=1, out_features=100),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(in_features=100, out_features=100),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(in_features=100, out_features=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Center data\n",
    "        x = x - 115 / 2\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "model = RegressionNetwork()\n",
    "print(summary(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fa62dd-3a38-4840-a76a-cf52695718de",
   "metadata": {},
   "source": [
    "The network is a dense neural network with two linear layers of 100\n",
    "units. This represents more than 10 000 parameters, which is\n",
    "(deliberately) quite big for modelling a dataset of 30 points.\n",
    "\n",
    "We will train this network for 3000 epochs, which, once again, seems\n",
    "quite a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training step\n",
    "def train_step(x, y, model, loss_fn, optimizer):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    # Reset gradients\n",
    "    optimizer.zero_grad()\n",
    "    # Forward pass: compute predicted values\n",
    "    y_pred = model(x)\n",
    "    # Compute loss\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    # Backpropagations\n",
    "    loss.backward()\n",
    "    # Parameters adjustment\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "\n",
    "# Loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "# Optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.005)\n",
    "\n",
    "# Run training\n",
    "epochs = 2000\n",
    "for epoch in range(epochs):\n",
    "    loss = train_step(time, score, model, loss_fn, optimizer)\n",
    "    if (epoch + 1) % 500 == 0:\n",
    "        print(f\"{epoch + 1:5}. loss: {loss:5.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e299e766-f4ae-4be3-a703-ec8b1cf4c23a",
   "metadata": {},
   "source": [
    "The training seems to be going fine, the loss is going down steadily and\n",
    "seems rather small after the last epoch.\n",
    "\n",
    "We can compare our model predictions *vs* the real ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_pred = model(time)\n",
    "cooking.scatter_plot_pred(time, score, score_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc23ea7-4e86-40b7-b493-cbb76abbd0ad",
   "metadata": {},
   "source": [
    "This seems quite good! Predicted values are not too far from the real\n",
    "ones, and even the outliers seem to be predicted correctly.\n",
    "\n",
    "But let’s try now to visualize what the predicted values would be for\n",
    "values in the range of \\[5, 120\\] cooking time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "cooking.line_plot(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888265da-65ee-4e99-8d64-186d17b8d354",
   "metadata": {},
   "source": [
    "This doesn’t look like the parabolic distribution we had intuitively\n",
    "seen by looking at our dataset. By adjusting to the outliers, the model\n",
    "is diverging from the “true” data distribution.\n",
    "\n",
    "Suppose we get a new sample dataset, this time without outliers. By\n",
    "applying our trained model to these new values we can predict their\n",
    "scores and compare with the real ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new data\n",
    "time_new, score_new = cooking.generate_data(size=20)\n",
    "\n",
    "# Compute and plot predicted scores vs true scores\n",
    "score_new_pred = model(time_new)\n",
    "cooking.scatter_plot_pred(time_new, score_new, score_new_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009e1bea-9dbb-4cee-8879-de5d004d07d9",
   "metadata": {},
   "source": [
    "The results are rather good except for the points which are around the\n",
    "original outliers time values: in these cases the predicted values are\n",
    "quite far from the real ones.\n",
    "\n",
    "This is an example of **overfitting**: by being too close to our\n",
    "training data, our model doesn’t *generalize* well to new data.\n",
    "\n",
    "Overfitting is a frequent problem in deep learning, and there are\n",
    "several methods to try to limit it. Some of these methods are linked to\n",
    "the network architecture: we can reduce the number of parameters to\n",
    "avoid the model to learn “too much”, or we can introduce some specific\n",
    "layers such as dropout layers to help the model generalize better.\n",
    "\n",
    "In the following we will talk about another way to limit overfitting by\n",
    "not training our model for too long.\n",
    "\n",
    "## Validation data\n",
    "\n",
    "One way to limit overfitting is by splitting our training dataset in two\n",
    "parts: a training set and a validation set. The model will be trained\n",
    "only on the training set (it will never see the validation data during\n",
    "training), but after each epoch we will compute the loss both on the\n",
    "train set and on the validation set.\n",
    "\n",
    "Let’s try in our example by creating a small random validation data set\n",
    "without outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_valid, score_valid = cooking.generate_data(size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6527964f-8de3-4fd5-a807-b49bf8a9881c",
   "metadata": {},
   "source": [
    "We modify our training step to compute the loss on the validation\n",
    "dataset at the end of each step, after the parameters have been\n",
    "adjusted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step_with_validation(x, y, x_valid, y_valid, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(x)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Compute validation loss\n",
    "    model.eval()\n",
    "    valid_pred = model(x_valid)\n",
    "    valid_loss = loss_fn(valid_pred, y_valid)\n",
    "\n",
    "    return loss, valid_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7c6438-7e58-4a7d-a790-11ad98f9f9de",
   "metadata": {},
   "source": [
    "We can now run this new training process. The model architecture is the\n",
    "same, the train set is the same as the one from our previous example,\n",
    "but we add a validation set that we preprocess and scale in the same way\n",
    "as the train set.\n",
    "\n",
    "We then train the model for 1000 epochs (and with a smaller learning\n",
    "rate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RegressionNetwork()\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.005)\n",
    "\n",
    "results = []\n",
    "\n",
    "epochs = 2000\n",
    "for epoch in range(epochs):\n",
    "    loss, valid_loss = train_step_with_validation(\n",
    "        time, score, time_valid, score_valid, model, loss_fn, optimizer\n",
    "    )\n",
    "    if (epoch + 1) % 200 == 0:\n",
    "        print(f\"{epoch + 1:5}. loss: {loss:5.3f}, valid_loss: {valid_loss:5.3f}\")\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        results.append({\"epoch\": epoch + 1, \"loss\": loss, \"valid_loss\": valid_loss})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8563606c-d477-4ffe-a378-d744393591d3",
   "metadata": {},
   "source": [
    "We can see that the train loss is still going down until 2000 epochs,\n",
    "but if we look at the validation loss, it goes down quite fast but then\n",
    "starts to go up after about 1000 epochs.\n",
    "\n",
    "We can represent both losses in a line plot to better visualize the\n",
    "process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pl.DataFrame(results).unpivot(index=\"epoch\", on=[\"loss\", \"valid_loss\"])\n",
    "\n",
    "(\n",
    "    pn.ggplot(d, pn.aes(x=\"epoch\", y=\"value\", color=\"variable\"))\n",
    "    + pn.geom_line()\n",
    "    + pn.scale_y_continuous(limits=[0, None])  # type: ignore\n",
    "    + pn.labs(color=\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b891d90-61b2-4f3b-b9b1-64f7b01b18ec",
   "metadata": {},
   "source": [
    "The graph allows to see that until about epoch 1000, both losses go down\n",
    "fast. But after that, their evolution is inverted: the train loss goes\n",
    "down slowly, but the validation loss starts to go up at about the same\n",
    "speed.\n",
    "\n",
    "Intuitively, we can imagine that the first 1000 epochs are used to learn\n",
    "the parabolic distribution, which corresponds to both the train and\n",
    "validation datasets. But after that the only way to lower the train loss\n",
    "is to adapt to the individual data points in the train set, and in\n",
    "particular the three outliers. This allows to improve the train loss,\n",
    "but by doing that the model goes away from the “real” distribution, and\n",
    "so the validation loss goes up.\n",
    "\n",
    "By using both a training and a validation dataset and monitoring their\n",
    "loss at each epoch, you can determine if and when the validation loss\n",
    "begins to increase. If this occurs, it indicates overfitting, suggesting\n",
    "that training should be halted around the corresponding epoch.\n",
    "\n",
    "A good way to do this is to keep track of the validation loss at each\n",
    "epoch, and to save the model corresponding to the lowest validation loss\n",
    "reached during the training process.\n",
    "\n",
    "The following code shows a way to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RegressionNetwork()\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.005)\n",
    "\n",
    "best_model = copy.deepcopy(model)\n",
    "best_loss = np.inf\n",
    "best_epoch = None\n",
    "\n",
    "epochs = 2000\n",
    "for epoch in range(epochs):\n",
    "    loss, valid_loss = train_step_with_validation(\n",
    "        time, score, time_valid, score_valid, model, loss_fn, optimizer\n",
    "    )\n",
    "    # We keep track of the model with the best results on the validation dataset\n",
    "    if valid_loss < best_loss:\n",
    "        # Store best model\n",
    "        best_model = copy.deepcopy(model)\n",
    "        # Keep track of best validation loss\n",
    "        best_loss = valid_loss\n",
    "        # Keep track of epoch for best validation loss\n",
    "        best_epoch = epoch\n",
    "    if (epoch + 1) % 200 == 0:\n",
    "        print(f\"{epoch + 1:5}. loss: {loss:5.3f}, valid_loss: {valid_loss:5.3f}\")\n",
    "\n",
    "print(f\"\\nBest validation loss: {best_loss:.3f}, reached at epoch {best_epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a23164-cff1-4dcf-9b93-1c98c3114ccf",
   "metadata": {},
   "source": [
    "If we plot the predicted values of our “best” model, we can see that it\n",
    "didn’t adjust to the outliers in our train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score_pred = best_model(time)\n",
    "cooking.scatter_plot_pred(time, score, best_score_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3deaaba0-148a-4574-b482-109757e3f5eb",
   "metadata": {},
   "source": [
    "And if we plot the predicted values for the whole range of cooking\n",
    "times, we can see that we are closer to the previously guessed parabolic\n",
    "distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": [
    "cooking.line_plot(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5ecf46-da2f-443b-992e-f8f8a6aef3bc",
   "metadata": {},
   "source": [
    "## Test data\n",
    "\n",
    "Using a validation dataset is good, but it is still possible that our\n",
    "model will overfit on this validation data. How? Imagine we run the\n",
    "training process a great number of times, to modify the network\n",
    "architecture, to evaluate different optimizers, to modify the learning\n",
    "rate, etc.\n",
    "\n",
    "During each training process we will use our validation dataset to\n",
    "assess the quality of our results. By doing so, we tend to adjust our\n",
    "hyperparameters and network architecture to this validation dataset,\n",
    "which can lead to a form of overfitting and degrade the model’s\n",
    "generalization ability.\n",
    "\n",
    "To prevent this, we can add a third dataset, which is called the *test*\n",
    "dataset. These are the data that will be used to compute the final\n",
    "quality of our results.\n",
    "\n",
    "## Exercise\n",
    "\n",
    "Generate a small test dataset of size 20, and compute the loss on this\n",
    "test dataset on our best model computed previously.\n",
    "\n",
    "So, as a recap, our training (labelled) data can be split into three\n",
    "datasets:\n",
    "\n",
    "-   the *train* dataset is used to train the model and adjust its\n",
    "    parameters\n",
    "-   the *validation* dataset is used to evaluate the loss at the end of\n",
    "    each epoch and prevent overfitting by selecting the best model based\n",
    "    on this validation loss\n",
    "-   the *test* dataset is used at the end of all the model tuning and\n",
    "    training processes to assess the final quality of its results based\n",
    "    on data never seen beforehand\n",
    "\n",
    "Ideally, the test dataset should be used once and only once. It is\n",
    "sometimes difficult in practice, but in any case it should be used (and\n",
    "seen by the model) as infrequently as possible."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": "3"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
