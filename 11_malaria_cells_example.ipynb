{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12145bcd-7bc1-43f1-af51-090e2c9a4e55",
   "metadata": {},
   "source": [
    "# Malaria cells complete example\n",
    "\n",
    "**Note :** to use this notebook in Google Colab, create a new cell with\n",
    "the following lines and run it.\n",
    "\n",
    "```shell\n",
    "!git clone https://gitlab.in2p3.fr/jbarnier/ateliers_deep_learning.git\n",
    "%cd ateliers_deep_learning\n",
    "!pip install .\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotnine as pn\n",
    "import polars as pl\n",
    "import torch\n",
    "from PIL import Image\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchmetrics import MetricCollection\n",
    "from torchmetrics.classification import (\n",
    "    MulticlassAccuracy,\n",
    "    MulticlassConfusionMatrix,\n",
    "    MulticlassPrecision,\n",
    "    MulticlassRecall,\n",
    ")\n",
    "from torchvision.transforms import v2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c99d8f-1036-4d2b-91cc-be6bebb080eb",
   "metadata": {},
   "source": [
    "In this notebook we will implement a complete training process using the\n",
    "[Malaria cells\n",
    "image](https://www.kaggle.com/datasets/iarunava/cell-images-for-detecting-malaria)\n",
    "dataset, which has been built from the [Malaria screener\n",
    "project](https://lhncbc.nlm.nih.gov/LHC-research/LHC-projects/image-processing/malaria-project.html).\n",
    "It will be quite close to the previous sign language notebook, the main\n",
    "difference being that input data is provided as image files instead of a\n",
    "precomputed data frame.\n",
    "\n",
    "The dataset contains about 27 000 cell images, half of them being\n",
    "infected by malaria. Images have been reduced to 28x28 pixels and\n",
    "converted to grayscale. The image files are available in the\n",
    "`data/malaria_cells/parasitized` and `data/malaria_cells/uninfected`\n",
    "directories.\n",
    "\n",
    "We can display randomly chosen parasitized and uninfected image cells.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "uninfected_imgs = list(Path(\"data/malaria_cells/uninfected\").glob(\"*.jpg\"))\n",
    "parasitized_imgs = list(Path(\"data/malaria_cells/parasitized\").glob(\"*.jpg\"))\n",
    "\n",
    "u_img = random.choice(uninfected_imgs)\n",
    "p_img = random.choice(parasitized_imgs)\n",
    "fig, ax = plt.subplots(ncols=2)\n",
    "ax[0].imshow(Image.open(u_img), cmap=\"gray\")\n",
    "ax[0].set_title(f\"{u_img.stem} - Uninfected\")\n",
    "ax[1].imshow(Image.open(p_img), cmap=\"gray\")\n",
    "ax[1].set_title(f\"{p_img.stem} - Parasitized\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d401cd58-95f1-4fb8-8d42-fb09f19f469a",
   "metadata": {},
   "source": [
    "## Datasets and dataloaders\n",
    "\n",
    "First thing we have to do is to manage data loading and mini-batches\n",
    "creation. Here our input data are image files, and their labels is\n",
    "implicitly given by their directory (`parasitized` or `uninfected`).\n",
    "\n",
    "To manage our input data we create a `CellsDataset` class. The class\n",
    "constructor will load all image files, convert them to tensors and scale\n",
    "their pixel values between 0 and 1 using `torchvision`. Images tensors\n",
    "are stored in an `images` dictionary with image filenames as keys, and\n",
    "the labels are stored in a corresponding `labels` dictionary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img_file):\n",
    "    \"\"\"\n",
    "    Load and process an image file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img_file : str\n",
    "        Path to the image file to be processed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        Processed image as a tensor.\n",
    "    \"\"\"\n",
    "    # Define transformation pipeline: convert to torchvision image,\n",
    "    # then to a scaled tensor\n",
    "    transform = v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])\n",
    "    # Read image and apply pipeline\n",
    "    img = Image.open(img_file)\n",
    "    img = transform(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "class CellsDataset(Dataset):\n",
    "    def __init__(self, uninfected_path, parasitized_path) -> None:\n",
    "        u_imgs = Path(uninfected_path).glob(\"*.jpg\")\n",
    "        p_imgs = Path(parasitized_path).glob(\"*.jpg\")\n",
    "\n",
    "        # Initialize images and labels dictionaries\n",
    "        self.images = {}\n",
    "        self.labels = {}\n",
    "\n",
    "        # Process uninfected images (label 0)\n",
    "        for img_file in u_imgs:\n",
    "            filename = img_file.stem\n",
    "            img = process_image(img_file)\n",
    "            self.images[filename] = img\n",
    "            self.labels[filename] = torch.tensor(0)\n",
    "\n",
    "        # Process parasitized images (label 1)\n",
    "        for img_file in p_imgs:\n",
    "            filename = img_file.stem\n",
    "            img = process_image(img_file)\n",
    "            self.images[filename] = img\n",
    "            self.labels[filename] = torch.tensor(1, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        key = list(self.labels.keys())[index]\n",
    "        # Returns the (image, label) pair of the given index\n",
    "        return self.images[key], self.labels[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e95f15-066f-46bf-8008-d46af08d4ca5",
   "metadata": {},
   "source": [
    "We use our class to create a new dataset object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CellsDataset(\n",
    "    uninfected_path=\"data/malaria_cells/uninfected\",\n",
    "    parasitized_path=\"data/malaria_cells/parasitized\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfeebdd-63b9-4fbd-959a-ade3080a1f4d",
   "metadata": {},
   "source": [
    "We then split this dataset into a training, validation, and test sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = random_split(dataset, [0.7, 0.2, 0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652c8009-2a50-4511-a2bc-8e340d469476",
   "metadata": {},
   "source": [
    "We can confirm that our data is in good shape by plotting an image and\n",
    "its label at a given index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(data, index):\n",
    "    img, label = data[index]\n",
    "    plt.imshow(img.reshape(28, 28), cmap=\"gray\")\n",
    "    plt.title(f\"Label: {label.item()}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Display a random image\n",
    "index = random.randint(0, len(train_data))\n",
    "show_image(train_data, index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2b2adb-a7e3-42c4-ae73-62e5dd65f939",
   "metadata": {},
   "source": [
    "Finally, we define a small function which will create three data loaders\n",
    "for our training, validation and test datasets for a given batch size.\n",
    "The training set is shuffled at each epoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_loaders(batch_size):\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_data, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, valid_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311ef7e8-f7f9-43c8-a6a1-a44c3a80ff0e",
   "metadata": {},
   "source": [
    "## Training code\n",
    "\n",
    "We now detect what device the training process will run on. It will be\n",
    "either `\"cuda\"` if a GPU is available, or `\"cpu\"` otherwise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Running on: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c679fef-bfcc-4cb3-94c0-915a9247a95a",
   "metadata": {},
   "source": [
    "There are many ways to organize the training process and its code in\n",
    "pytorch, the one presented here is just one way to do it among many\n",
    "others. Feel free to check one of the many tutorials available online to\n",
    "see which type of code organization suits you best.\n",
    "\n",
    "Here we organize the different functions and attributes in a custom\n",
    "`Training` class:\n",
    "\n",
    "-   The class constructor gets some model hyperparameters as arguments\n",
    "    and store them as object attributes. It also defines and stores a\n",
    "    loss function, the optimizer and the metrics computed to evaluate\n",
    "    the results.\n",
    "-   The `train_loop` method runs the training for one epoch using a\n",
    "    training dataloader.\n",
    "-   The `eval_loop` method computes loss and metrics on a given loader\n",
    "    in evaluation mode (without backpropagation). It is used to evaluate\n",
    "    the model on the validation dataset during training (or on the test\n",
    "    dataset post-training).\n",
    "-   The main `train` method runs the training by running the\n",
    "    `train_loop` on the train loader for a given number of epochs. At\n",
    "    the end of each epoch it also calls `eval_loop` on the validation\n",
    "    dataset.\n",
    "-   We use `torchmetrics` to compute the metrics more easily across\n",
    "    batches.\n",
    "-   During training, the best model (the one with the lowest validation\n",
    "    loss) is saved to disk with the `save_model` method. At the end of\n",
    "    the training, the best model is loaded with `load_best_model` as our\n",
    "    `model` attribute so that it will be easily used in the rest of the\n",
    "    notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "    def __init__(\n",
    "        self, model: nn.Module, device: str, learning_rate: float, model_path: str\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Training process class.\n",
    "\n",
    "        Args:\n",
    "            model (nn.Module): model to be trained.\n",
    "            device (str): device to be used (\"cpu\" or \"cuda\").\n",
    "            learning_rate (float): learning rate.\n",
    "            model_path (str): path where the best model will be saved during training.\n",
    "        \"\"\"\n",
    "        self.device = device\n",
    "        # Save the model as attribute and send it to device\n",
    "        self.model = model.to(self.device)\n",
    "        # Loss function\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Optimizer\n",
    "        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=learning_rate)  # type: ignore\n",
    "        self.n_classes = 2\n",
    "\n",
    "        # Path to save best model\n",
    "        best_model_path = Path(model_path)\n",
    "        if not best_model_path.exists():\n",
    "            best_model_path.mkdir(exist_ok=True)\n",
    "        # File to save best model\n",
    "        self.best_model_path = Path(best_model_path) / \"model_best.pt\"\n",
    "\n",
    "        # Attribute to store loss values during training process\n",
    "        self.train_history = None\n",
    "\n",
    "        # Metrics\n",
    "        self.metrics = MetricCollection(\n",
    "            {\n",
    "                # Global accuracy\n",
    "                \"accuracy\": MulticlassAccuracy(\n",
    "                    num_classes=self.n_classes, average=\"micro\"\n",
    "                ),\n",
    "                # Confusion matrix\n",
    "                \"confusion_matrix\": MulticlassConfusionMatrix(\n",
    "                    num_classes=self.n_classes\n",
    "                ),\n",
    "                # Precision for each label\n",
    "                \"precision\": MulticlassPrecision(\n",
    "                    num_classes=self.n_classes, average=None\n",
    "                ),\n",
    "                # Recall for each label\n",
    "                \"recall\": MulticlassRecall(num_classes=self.n_classes, average=None),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def train_loop(self, loader: DataLoader) -> float:\n",
    "        \"\"\"\n",
    "        Training loop for one epoch.\n",
    "\n",
    "        Args:\n",
    "            loader (DataLoader): loader to use for the training loop.\n",
    "\n",
    "        Returns:\n",
    "            float: average loss value.\n",
    "        \"\"\"\n",
    "        # Set the model to training mode\n",
    "        self.model.train()\n",
    "        loss = 0\n",
    "        # Iterate through all batches\n",
    "        for input, target in loader:\n",
    "            input = input.to(self.device)\n",
    "            target = target.to(self.device)\n",
    "            # Reset gradients\n",
    "            self.optimizer.zero_grad()\n",
    "            # Forward pass: compute predicted values and loss\n",
    "            pred = self.model(input)\n",
    "            batch_loss = self.loss_fn(pred, target)\n",
    "            # Backpropagation\n",
    "            batch_loss.backward()\n",
    "            self.optimizer.step()\n",
    "            # Store loss\n",
    "            loss_value = batch_loss.item()\n",
    "            loss += loss_value\n",
    "        # Compute average loss\n",
    "        loss /= len(loader)  # type: ignore\n",
    "        return loss\n",
    "\n",
    "    @torch.no_grad\n",
    "    def eval_loop(self, loader: DataLoader) -> tuple:\n",
    "        \"\"\"\n",
    "        Compute loss, accuracy and confusion matrix for the current model and the\n",
    "        given loader.\n",
    "\n",
    "        Args:\n",
    "            loader (DataLoader): loader to use to evaluate the model.\n",
    "\n",
    "        Returns:\n",
    "            tuple: tuple of loss value, metrics dictionary.\n",
    "        \"\"\"\n",
    "        eval_loss = 0\n",
    "        # Set model to evaluation mode\n",
    "        self.model.eval()\n",
    "        # Iterate through batches\n",
    "        for input, target in loader:\n",
    "            input = input.to(self.device)\n",
    "            target = target.to(self.device)\n",
    "            # Compute batch loss\n",
    "            pred = self.model(input)\n",
    "            batch_loss = self.loss_fn(pred, target).item()\n",
    "            eval_loss += batch_loss\n",
    "            # Update metrics\n",
    "            self.metrics.update(pred, target)\n",
    "        # Compute average loss\n",
    "        eval_loss /= len(loader)\n",
    "        # Compute and reset metrics\n",
    "        metrics = self.metrics.compute()\n",
    "        self.metrics.reset()\n",
    "\n",
    "        return eval_loss, metrics  # type: ignore\n",
    "\n",
    "    def train(\n",
    "        self, train_loader: DataLoader, valid_loader: DataLoader, epochs: int\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Main training method. Run the training loop for a given number of epochs.\n",
    "\n",
    "        Args:\n",
    "            train_loader (DataLoader): train data loader.\n",
    "            valid_loader (DataLoader): validation data loader.\n",
    "            epochs (int): number of epochs to run.\n",
    "        \"\"\"\n",
    "        # Reset train attributes\n",
    "        self.train_history = []\n",
    "        best_loss = float(\"inf\")\n",
    "        best_epoch = None\n",
    "\n",
    "        # Record start time\n",
    "        start_time = time.time()\n",
    "\n",
    "        print(\"Epoch   Train loss   Valid loss    Valid acc    Best\")\n",
    "        print(\"----------------------------------------------------\")\n",
    "\n",
    "        # For each epoch\n",
    "        for epoch in range(epochs):\n",
    "            # Run the training loop on train data\n",
    "            loss = self.train_loop(train_loader)\n",
    "            # Evaluate metrics on validation data\n",
    "            valid_loss, metrics = self.eval_loop(valid_loader)\n",
    "            # Check if the current model is the best one\n",
    "            best = valid_loss < best_loss\n",
    "            if best:\n",
    "                best_epoch = epoch + 1\n",
    "                best_loss = valid_loss\n",
    "                self.save_model()\n",
    "\n",
    "            # Display results\n",
    "            valid_acc = metrics[\"accuracy\"].item()\n",
    "            print(\n",
    "                f\"{epoch + 1:5}   {loss:10.3f}   {valid_loss:10.3f}   {valid_acc:10.3f}\"\n",
    "                f\"    {'*' if best else '':>4}\"\n",
    "            )\n",
    "            # Store losses in train history\n",
    "            self.train_history.append({\"epoch\": epoch, \"type\": \"train\", \"loss\": loss})\n",
    "            self.train_history.append(\n",
    "                {\"epoch\": epoch, \"type\": \"valid\", \"loss\": valid_loss}\n",
    "            )\n",
    "\n",
    "        # Display training time\n",
    "        training_time = time.time() - start_time\n",
    "        print(f\"\\nTraining time: {timedelta(seconds=round(training_time))}\")\n",
    "\n",
    "        # Load and evaluate best model and display results\n",
    "        self.load_best_model()\n",
    "        valid_loss, valid_metrics = self.eval_loop(valid_loader)\n",
    "        valid_acc = valid_metrics[\"accuracy\"].item()\n",
    "        print(\n",
    "            f\"Best model at epoch {best_epoch}, valid_loss: {valid_loss:5.3f},\"\n",
    "            f\" valid_accuracy: {valid_acc:5.3f}\"\n",
    "        )\n",
    "\n",
    "    def save_model(self) -> None:\n",
    "        \"\"\"\n",
    "        Save the current model state to the best model path.\n",
    "        \"\"\"\n",
    "        torch.save(self.model.state_dict(), self.best_model_path)\n",
    "\n",
    "    def load_best_model(self) -> None:\n",
    "        \"\"\"\n",
    "        Restore the current model from the best model path.\n",
    "        \"\"\"\n",
    "        state_dict = torch.load(self.best_model_path, weights_only=False)\n",
    "        self.model.load_state_dict(state_dict)\n",
    "        self.model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e5b05c-b7d7-4963-b5b4-b1ed38b27cd1",
   "metadata": {},
   "source": [
    "## Dense network training\n",
    "\n",
    "For this example we will use a simple dense network. It first flattens\n",
    "our image data to a single 784 values tensor, and then passes it through\n",
    "three layers to bring it down to 2 values, _ie_ the number of classes we\n",
    "want to predict.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4be826-6967-4b8d-aef2-b406bcdac46f",
   "metadata": {},
   "source": [
    "We define our training hyperparameters such as batch size and learning\n",
    "rate, and we create a new `Training object`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "epochs = 20\n",
    "best_model_path = \"out_malaria_cells_dense\"\n",
    "\n",
    "# Generate DataLoaders with the given batch size\n",
    "train_loader, valid_loader, test_loader = generate_loaders(batch_size=batch_size)\n",
    "# Create a SignTraining object\n",
    "training = Training(\n",
    "    model=DenseNetwork(),\n",
    "    device=DEVICE,\n",
    "    learning_rate=learning_rate,\n",
    "    model_path=best_model_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd36293-442a-4831-8355-db6259d0ba0f",
   "metadata": {},
   "source": [
    "We can then launch our network training process:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training\n",
    "training.train(train_loader, valid_loader, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b9885b-696a-4a9e-9eff-3ec2d80dfa57",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "When the training has ended we can try to visualize and evaluate the\n",
    "model results.\n",
    "\n",
    "First we can plot the loss values at each epoch:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pn.ggplot(\n",
    "        pl.DataFrame(training.train_history), pn.aes(x=\"epoch\", y=\"loss\", color=\"type\")\n",
    "    )\n",
    "    + pn.geom_line()\n",
    "    + pn.scale_y_continuous(limits=(0, None))  # type: ignore\n",
    "    + pn.labs(color=\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b7c923-03f8-4487-9770-7d05f2cc0520",
   "metadata": {},
   "source": [
    "We may also want to evaluate our model on the test set:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, metrics = training.eval_loop(test_loader)\n",
    "print(f\"Test loss: {loss:.3f}\")\n",
    "print(f\"Test accuracy: {metrics['accuracy']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733efb6f-5d5f-45df-aec6-a4de120246f4",
   "metadata": {},
   "source": [
    "We can plot the confusion matrix for our results:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-31",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics[\"confusion_matrix\"].numpy()\n",
    "ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f67d1c-19fd-4875-829f-672395401fd7",
   "metadata": {},
   "source": [
    "We can display precision and recall values for each label:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-33",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pl.DataFrame(\n",
    "    {\n",
    "        \"label\": [0, 1],\n",
    "        \"precision\": (metrics[\"precision\"] * 100).numpy(),\n",
    "        \"recall\": (metrics[\"recall\"] * 100).numpy(),\n",
    "    }\n",
    ")\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83073a9-cab0-4906-beea-5840537d9192",
   "metadata": {},
   "source": [
    "## Exercise : CNN network training\n",
    "\n",
    "In this notebook we used a dense feed-forward neural network to classify\n",
    "images, but there are other network architectures that are much more\n",
    "suitable. In particular, Convolutional Neural Networks (CNN) are very\n",
    "good at detecting patterns in images which can then be used for tasks\n",
    "such as classification.\n",
    "\n",
    "Here is an example of CNN network architecture that could be used for\n",
    "our problem:\n",
    "\n",
    "```py\n",
    "self.network = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, stride=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=8, out_channels=4, kernel_size=3, stride=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(576, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 2),\n",
    ")\n",
    "```\n",
    "\n",
    "Create a new `CNNCellsNetwork` class that implements this architecture,\n",
    "and train a new model from this class for 20 epochs. After that,\n",
    "evaluate the trained model on the test dataset.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": "3"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
