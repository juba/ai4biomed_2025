{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fb46a2c-3c38-4239-a03c-dc5b14199468",
   "metadata": {},
   "source": [
    "# Optimizers and schedulers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotnine as pn\n",
    "import torch\n",
    "\n",
    "from adl import optimizers\n",
    "\n",
    "pn.theme_set(\n",
    "    pn.theme_minimal()\n",
    "    + pn.theme(\n",
    "        plot_background=pn.element_rect(fill=\"white\"),\n",
    "        plot_title=pn.element_text(size=11),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd6ccb8-c780-4437-b2c3-b6fbc40d785f",
   "metadata": {},
   "source": [
    "Optimizers and schedulers are techniques and methods to improve the\n",
    "training process and find better optimum values. The goal of this\n",
    "notebook is to introduce some ideas about the way these methods work.\n",
    "\n",
    "## Optimizers\n",
    "\n",
    "In the previous notebooks we modified the parameters of our models from\n",
    "our gradient values manually, with code like the following:\n",
    "\n",
    "``` python\n",
    "w = w - step_size * w.grad\n",
    "b = b - step_size * b.grad\n",
    "```\n",
    "\n",
    "That is, at each training step our parameters (here $w$ and $b$) were\n",
    "adjusted by adding to their value the value of the loss gradient\n",
    "multiplied by a *step size* (also called *learning rate*). The learning\n",
    "rate measures how much we want to move in the gradient direction at each\n",
    "step, which could be roughly seen as how fast we want to learn from the\n",
    "gradient value at each step.\n",
    "\n",
    "This simple method allows to find the optimum values for the simplest\n",
    "cases, but it can be improved strongly with different techniques. A\n",
    "method to update the model parameters from their gradient values is\n",
    "called an *optimizer*.\n",
    "\n",
    "To illustrate this, we will use a more complex loss functions of two\n",
    "parameters with several different optimums. It is plotted below as a\n",
    "contour plot: the $x$ and $y$ axis show the values of our two\n",
    "parameters, and the colored contours represent the loss value at\n",
    "different points. When the contour is red the loss is high, when it is\n",
    "dark blue it is low. So our objective here is to start from a random\n",
    "point and reach the visible minimum which is around (-3, -2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sin_loss_args = {\n",
    "    \"loss_fn\": optimizers.sin_loss_fn,\n",
    "    \"w1min\": -14,\n",
    "    \"w1max\": 0,\n",
    "    \"w2min\": -6,\n",
    "    \"w2max\": 12,\n",
    "    \"nsteps\": 100,\n",
    "}\n",
    "optimizers.plot_loss(**plot_sin_loss_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2087d3d0-5c8c-409e-85fa-932a4a7af579",
   "metadata": {},
   "source": [
    "In the following plot, we represent the gradient descent starting from\n",
    "(-6.5, 4.5) and using a step size, or learning rate, of 0.01. So at each\n",
    "step we compute the loss gradient at the current point and we “move”\n",
    "along this direction according to the learning rate. We can see that in\n",
    "this case, we reach the minimal value in about 30 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sin_train_args1 = plot_sin_loss_args | {\n",
    "    \"w1_init\": -6.5,\n",
    "    \"w2_init\": 4.5,\n",
    "}\n",
    "optimizers.plot_train(**plot_sin_train_args1, epochs=30, step_size=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f515568c-d97d-48a1-aa37-f729b72c9d2d",
   "metadata": {},
   "source": [
    "### Stochastic gradient descent\n",
    "\n",
    "This method is called *stochastic gradient descent* and instead of\n",
    "computing it ourselves we can call the pytorch optimizer method\n",
    "`torch.optim.SGD` which by default does exactly the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sin_train_args1 = plot_sin_loss_args | {\n",
    "    \"w1_init\": -6.5,\n",
    "    \"w2_init\": 4.5,\n",
    "}\n",
    "optimizers.plot_train(\n",
    "    **plot_sin_train_args1,\n",
    "    epochs=30,\n",
    "    optimizer=torch.optim.SGD,  # type: ignore\n",
    "    optimizer_params={\"lr\": 0.01},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dc6f54-d90e-43c0-9bf3-3ffd03b57831",
   "metadata": {},
   "source": [
    "What would happen if we change the starting point? In the plot below we\n",
    "start from (-12, 10), and we can see that the gradient descent stops at\n",
    "another place, which is a local minimum with a higher value than the\n",
    "best visible one.\n",
    "\n",
    "This illustrates the fact that the training process is non\n",
    "deterministic: if we start at a random point, *ie* with our model\n",
    "parameters initialized with random values, the descent will be different\n",
    "and may not lead to the same optimum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sin_train_args2 = plot_sin_loss_args | {\n",
    "    \"w1_init\": -12.0,\n",
    "    \"w2_init\": 10.0,\n",
    "}\n",
    "optimizers.plot_train(\n",
    "    **plot_sin_train_args2,\n",
    "    epochs=30,\n",
    "    optimizer=torch.optim.SGD,  # type: ignore\n",
    "    optimizer_params={\"lr\": 0.01},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18279c88-6072-42c2-be48-3aa0821a2747",
   "metadata": {},
   "source": [
    "This also illustrates a drawback of the gradient descent method: if we\n",
    "stop at the first place we encounter where the gradient values are zero,\n",
    "we know we are at a minimum point, but it could be a local minimum\n",
    "instead of a global one. In fact, there is no way to know if the minimum\n",
    "is local or global.\n",
    "\n",
    "Several techniques have been developed to improve this behavior. One of\n",
    "them is to add *momentum* to our learning process: this can be seen as a\n",
    "way to add “inertia” to our descent, which can allow to escape from a\n",
    "local minimum in some cases. In the following example, we have the same\n",
    "starting point and learning rate as previously, but adding momentum\n",
    "allows to go beyond the first local minimum and towards the lower value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers.plot_train(\n",
    "    **plot_sin_train_args2,\n",
    "    epochs=25,\n",
    "    optimizer=torch.optim.SGD,  # type: ignore\n",
    "    optimizer_params={\"lr\": 0.01, \"momentum\": 0.6},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec9e679-4c97-4b35-8097-b21a3cecfdc7",
   "metadata": {},
   "source": [
    "Of course, the amount of momentum added is important: too few will not\n",
    "allow to escape from a local minimum, and too much can make the descent\n",
    "too fast and prevent from reaching the desired optimum, as in the\n",
    "following example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers.plot_train(\n",
    "    **plot_sin_train_args2,\n",
    "    epochs=15,\n",
    "    optimizer=torch.optim.SGD,  # type: ignore\n",
    "    optimizer_params={\"lr\": 0.01, \"momentum\": 0.8},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd7732f-924d-4996-aa83-79a95b6e1e3d",
   "metadata": {},
   "source": [
    "### Other optimizers\n",
    "\n",
    "Another limitation of stochastic gradient descent is that it uses a\n",
    "fixed learning rate, which is the same for each parameter at each\n",
    "training step. Other optimizers use adaptive learning rates, *ie* they\n",
    "adjust the values based on the previous gradient values: it steps down\n",
    "the learning rate for parameters with a history of high gradient values,\n",
    "and steps it up for parameters with low gradient values.\n",
    "\n",
    "We will illustrate this with another simpler loss function, still for\n",
    "two parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reg_loss_args = {\n",
    "    \"loss_fn\": optimizers.reg_loss_fn,\n",
    "    \"w1min\": -5,\n",
    "    \"w1max\": 5,\n",
    "    \"w2min\": -5,\n",
    "    \"w2max\": 5,\n",
    "    \"nsteps\": 100,\n",
    "}\n",
    "optimizers.plot_loss(**plot_reg_loss_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2578c0-d865-4b1b-bdbe-3eedf9e7475b",
   "metadata": {},
   "source": [
    "In the following plot we compare the `torch.optim.SGD` optimizer, with a\n",
    "fixed learning rate, and another optimizer called `torch.optim.RMSprop`,\n",
    "with adaptive learning rates. We can see that, for the same global\n",
    "learning rate, RMSprop will minimize oscillations by reducing the\n",
    "learning rates when the gradients have high values for several training\n",
    "steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reg_train_args = plot_reg_loss_args | {\n",
    "    \"w1_init\": -4.5,\n",
    "    \"w2_init\": -2.0,\n",
    "    \"optimum\": (0.0, 0.0),\n",
    "}\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "optimizers.plot_train(\n",
    "    **plot_reg_train_args,\n",
    "    epochs=50,\n",
    "    optimizer=torch.optim.SGD,  # type: ignore\n",
    "    optimizer_params={\"lr\": 0.5},\n",
    "    ax=ax1,\n",
    ")\n",
    "optimizers.plot_train(\n",
    "    **plot_reg_train_args,\n",
    "    epochs=50,\n",
    "    optimizer=torch.optim.RMSprop,  # type: ignore\n",
    "    optimizer_params={\"lr\": 0.5},\n",
    "    ax=ax2,\n",
    ")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df281452-89da-42ca-9cf7-93bae215b129",
   "metadata": {},
   "source": [
    "Another optimizer with adaptative learning rate is `torch.optim.AdamW`,\n",
    "which implements both adaptive learning rate and momentum. It also uses\n",
    "by default the notion of *weight decay*, which is a regularization\n",
    "technique that encourages smaller values for the parameters.\n",
    "\n",
    "When used in the same example with the same starting learning rate, we\n",
    "can see that this leads to a smoother descent, even if it is a bit\n",
    "slower at the start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers.plot_train(\n",
    "    **plot_reg_train_args,\n",
    "    epochs=80,\n",
    "    optimizer=torch.optim.AdamW,  # type: ignore\n",
    "    optimizer_params={\"lr\": 0.5},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d848d1fe-7ac3-44cd-97db-a5de74efd65f",
   "metadata": {},
   "source": [
    "If we increase the learning rate, we can see that the SGD descent starts\n",
    "to diverge and doesn’t reach the optimum value, whereas RMSprop still\n",
    "converges, and AdamW has almost the same descent, although a bit faster.\n",
    "This makes RMSprop and AdamW a bit less dependent on the initial\n",
    "learning rate value than SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))\n",
    "optimizers.plot_train(\n",
    "    **plot_reg_train_args,\n",
    "    epochs=10,\n",
    "    optimizer=torch.optim.SGD,  # type: ignore\n",
    "    optimizer_params={\"lr\": 0.6},\n",
    "    ax=ax1,\n",
    ")\n",
    "optimizers.plot_train(\n",
    "    **plot_reg_train_args,\n",
    "    epochs=50,\n",
    "    optimizer=torch.optim.RMSprop,  # type: ignore\n",
    "    optimizer_params={\"lr\": 0.6},\n",
    "    ax=ax2,\n",
    ")\n",
    "optimizers.plot_train(\n",
    "    **plot_reg_train_args,\n",
    "    epochs=70,\n",
    "    optimizer=torch.optim.Adam,  # type: ignore\n",
    "    optimizer_params={\"lr\": 0.6},\n",
    "    ax=ax3,\n",
    ")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411c3ff5-025a-4ec0-b8aa-97c7007d5295",
   "metadata": {},
   "source": [
    "Finally, we can compare the training process of SGD, RMSprop and AdamW\n",
    "on our complex loss example.\n",
    "\n",
    "First, for SGD, the result is highly dependant ont the initial learning\n",
    "rate. Furthermore, the fixed learning rate can lead to strong\n",
    "oscillations around the optimum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))\n",
    "optimizers.plot_train(\n",
    "    **plot_sin_train_args2,\n",
    "    epochs=60,\n",
    "    optimizer=torch.optim.SGD,  # type: ignore\n",
    "    optimizer_params={\"lr\": 0.03},\n",
    "    ax=ax1,\n",
    ")\n",
    "optimizers.plot_train(\n",
    "    **plot_sin_train_args2,\n",
    "    epochs=100,\n",
    "    optimizer=torch.optim.SGD,  # type: ignore\n",
    "    optimizer_params={\"lr\": 0.05},\n",
    "    ax=ax2,\n",
    ")\n",
    "optimizers.plot_train(\n",
    "    **plot_sin_train_args2,\n",
    "    epochs=60,\n",
    "    optimizer=torch.optim.SGD,  # type: ignore\n",
    "    optimizer_params={\"lr\": 0.07},\n",
    "    ax=ax3,\n",
    ")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f58718f-0f0c-430a-9072-f9ab22a87087",
   "metadata": {},
   "source": [
    "RMSprop is also quite dependent on the initial learning rate. If the\n",
    "value is too low we can be stuck in a local minimum, and if it is too\n",
    "high we can “escape” the visible global minimum and go beyond it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))\n",
    "optimizers.plot_train(\n",
    "    **plot_sin_train_args2,\n",
    "    epochs=60,\n",
    "    optimizer=torch.optim.RMSprop,  # type: ignore\n",
    "    optimizer_params={\"lr\": 0.3},\n",
    "    ax=ax1,\n",
    ")\n",
    "optimizers.plot_train(\n",
    "    **plot_sin_train_args2,\n",
    "    epochs=60,\n",
    "    optimizer=torch.optim.RMSprop,  # type: ignore\n",
    "    optimizer_params={\"lr\": 0.5},\n",
    "    ax=ax2,\n",
    ")\n",
    "optimizers.plot_train(\n",
    "    **plot_sin_train_args2,\n",
    "    epochs=60,\n",
    "    optimizer=torch.optim.RMSprop,  # type: ignore\n",
    "    optimizer_params={\"lr\": 0.6},\n",
    "    ax=ax3,\n",
    ")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5d0f67-8e0c-4ea6-9ea4-d6d4ac3b7a54",
   "metadata": {},
   "source": [
    "Finally, `AdamW` is less sensitive to the initial learning rate. Even\n",
    "with more extreme low and high values that our RMSprop example, it\n",
    "manages to reach the visible optimum with a smoother descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))\n",
    "optimizers.plot_train(\n",
    "    **plot_sin_train_args2,\n",
    "    epochs=150,\n",
    "    optimizer=torch.optim.AdamW,  # type: ignore\n",
    "    optimizer_params={\"lr\": 0.2},\n",
    "    ax=ax1,\n",
    ")\n",
    "optimizers.plot_train(\n",
    "    **plot_sin_train_args2,\n",
    "    epochs=50,\n",
    "    optimizer=torch.optim.AdamW,  # type: ignore\n",
    "    optimizer_params={\"lr\": 0.5},\n",
    "    ax=ax2,\n",
    ")\n",
    "optimizers.plot_train(\n",
    "    **plot_sin_train_args2,\n",
    "    epochs=35,\n",
    "    optimizer=torch.optim.AdamW,  # type: ignore\n",
    "    optimizer_params={\"lr\": 1.0},\n",
    "    ax=ax3,\n",
    ")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d595be44-1884-46dd-b520-ad80e6b3254b",
   "metadata": {},
   "source": [
    "## Schedulers\n",
    "\n",
    "Schedulers are another set of methods designed to improve the training\n",
    "process. The goal of a scheduler is to change the learning rate during\n",
    "the process.\n",
    "\n",
    "We will start with the following gradient descent example, with an `SGD`\n",
    "optimizer. We can see that with a learning rate of 0.04, the descent\n",
    "reaches the area of the visible minimum, but then it starts to oscillate\n",
    "around the minimum indefinitely instead of really reaching it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers.plot_train(\n",
    "    **plot_sin_train_args2,\n",
    "    epochs=250,\n",
    "    optimizer=torch.optim.SGD,  # type: ignore\n",
    "    optimizer_params={\"lr\": 0.04},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0da86f5-336e-4574-b318-2814483cc67e",
   "metadata": {},
   "source": [
    "This oscillation is due to the fixed value of the learning rate in\n",
    "`SGD`. The high learning rate is useful at the start of the training\n",
    "because it avoids a local minimum, but it becomes detrimental at the end\n",
    "because it prevents to stabilize and reach the optimum value.\n",
    "\n",
    "One way to work around this issue is to use a *scheduler* which will\n",
    "regularly decrease the learning rate along the training process. In the\n",
    "following example we use an `ExponentialLR` scheduler with a `gamma`\n",
    "argument of 0.95, which means that at every training step the learning\n",
    "rate will be multiplied by 0.95.\n",
    "\n",
    "This allows to avoid the oscillation problem at the end of the descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-31",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers.plot_train(\n",
    "    **plot_sin_train_args2,\n",
    "    epochs=30,\n",
    "    optimizer=torch.optim.SGD,  # type: ignore\n",
    "    optimizer_params={\"lr\": 0.04},\n",
    "    scheduler=torch.optim.lr_scheduler.ExponentialLR,\n",
    "    scheduler_params={\"gamma\": 0.95},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc04328f-9962-49b3-89fc-b70eae670269",
   "metadata": {},
   "source": [
    "There are many different schedulers available, such as\n",
    "`ReduceLROnPlateau` which will reduce the learning rate only if the loss\n",
    "value hasn’t gone down for a certain of training steps.\n",
    "\n",
    "Here we use it with a `factor` of 0.8 and a `patience` of 0, which means\n",
    "that the learning rate will be multiplied by 0.8 as soon as the loss\n",
    "value isn’t lower than the one of the previous step.\n",
    "\n",
    "We can see that this method also allows to avoid the oscillation problem\n",
    "at the end of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-33",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers.plot_train(\n",
    "    **plot_sin_train_args2,\n",
    "    epochs=20,\n",
    "    optimizer=torch.optim.SGD,  # type: ignore\n",
    "    optimizer_params={\"lr\": 0.04},\n",
    "    scheduler=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    scheduler_params={\"patience\": 0, \"factor\": 0.8},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd06a08-35bc-4637-a92f-6c700c7d4e42",
   "metadata": {},
   "source": [
    "Schedulers can be useful even for optimizers that use adaptive learning\n",
    "rate. If we use `RMSprop` in the previous example, we can see that we\n",
    "can still have the oscillation problem shown by `SGD`: at the end of the\n",
    "process, the model oscillates between two values around the optimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-35",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers.plot_train(\n",
    "    **plot_sin_train_args2,\n",
    "    epochs=150,\n",
    "    optimizer=torch.optim.RMSprop,  # type: ignore\n",
    "    optimizer_params={\"lr\": 0.4},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fe784c-2d0d-4bf0-9852-8cbd84d9d1e7",
   "metadata": {},
   "source": [
    "If we use a `ReduceLROnPlateau` scheduler, the oscillation problem goes\n",
    "away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-37",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers.plot_train(\n",
    "    **plot_sin_train_args2,\n",
    "    epochs=30,\n",
    "    optimizer=torch.optim.RMSprop,  # type: ignore\n",
    "    optimizer_params={\"lr\": 0.4},\n",
    "    scheduler=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    scheduler_params={\"patience\": 0, \"factor\": 0.9},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd0afec-cdf5-472c-9bec-a54e4801549b",
   "metadata": {},
   "source": [
    "Finally, we can see that more modern optimizers like `AdamW` don’t seem\n",
    "to have the same issue as they will better adapt the learning rate by\n",
    "themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-39",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers.plot_train(\n",
    "    **plot_sin_train_args2,\n",
    "    epochs=50,\n",
    "    optimizer=torch.optim.AdamW,  # type: ignore\n",
    "    optimizer_params={\"lr\": 0.5},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b05ddd6-4fa7-4463-a134-945e23343220",
   "metadata": {},
   "source": [
    "However, other types of schedulers can be used with these optimizers\n",
    "especially with bigger models, for example to introduce a warmup period\n",
    "at the start of training. In this case, the learning rate starts from a\n",
    "small value and increases gradually to the desired starting learning\n",
    "rate along a few epochs.\n",
    "\n",
    "## Optimizers and schedulers in pytorch\n",
    "\n",
    "### Optimizers\n",
    "\n",
    "In the previous notebooks we didn’t use pytorch optimizers but adjusted\n",
    "our parameters manually.\n",
    "\n",
    "To use a pytorch defined optimizer we must first create an optimizer\n",
    "instance by invoking an optimizer method form `torch.optim`, like\n",
    "`torch.optim.SGD` or `torch.optim.AdamW`. We pass our model parameters\n",
    "as first argument, followed by other method arguments such as the\n",
    "learning rate.\n",
    "\n",
    "For example, to create an `SGD` optimizer on two model parameters `w`\n",
    "and `b` with a learning rate of 0.001:\n",
    "\n",
    "``` python\n",
    "optimizer = torch.optim.SGD([w, b], lr=0.001)\n",
    "```\n",
    "\n",
    "After that, we get two methods we can use in our training loop:\n",
    "\n",
    "-   `optimizer.step()` will adjust the values of the parameters based on\n",
    "    their gradients\n",
    "-   `optimizer.zero_grad()` will reset the gradient values.\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "Change the following training code seen in the previous notebook, by\n",
    "using a `torch.optimizer.SGD` optimizer with a learning rate of 0.001.\n",
    "Check that both code give the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x and y data\n",
    "x = torch.tensor([-1.5, 0.2, 3.4, 4.1, 7.8, 13.4, 18.0, 21.5, 32.0, 33.5])\n",
    "y = torch.tensor([100.5, 110.2, 133.5, 141.2, 172.8, 225.1, 251.0, 278.9, 366.7, 369.9])\n",
    "\n",
    "# Parameters\n",
    "w = torch.tensor(0.0, requires_grad=True)\n",
    "b = torch.tensor(0.0, requires_grad=True)\n",
    "\n",
    "\n",
    "def forward(x):\n",
    "    return w * x + b\n",
    "\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "step_size = 0.001\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    y_pred = forward(x)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    loss.backward()\n",
    "\n",
    "    # weight and bias adjustment\n",
    "    w.data = w.data - step_size * w.grad  # type: ignore\n",
    "    b.data = b.data - step_size * b.grad  # type: ignore\n",
    "\n",
    "    # reset gradients\n",
    "    w.grad.zero_()  # type: ignore\n",
    "    b.grad.zero_()  # type: ignore\n",
    "\n",
    "    print(f\"Epoch: {epoch}, loss: {loss:.2f}, weight: {w:.3f}, bias: {b:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173ad63a-95a2-408f-a9a5-805cc2c10fea",
   "metadata": {},
   "source": [
    "### Schedulers\n",
    "\n",
    "To use a pytorch scheduler in our training process, we have to create a\n",
    "scheduler instance by passing it our optimizer object and additional\n",
    "arguments. For example, to use a `ReduceLROnPlateau` scheduler:\n",
    "\n",
    "``` python\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.9)\n",
    "```\n",
    "\n",
    "After that, we can use the method `scheduler.step()` at the end of each\n",
    "epoch to modify our optimizer learning rate.\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "Modify the answer of the previous exercise to use a\n",
    "`torch.optim.lr_scheduler.ExponentialLR` scheduler with a `gamma`\n",
    "argument of 0.95."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": "3"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
