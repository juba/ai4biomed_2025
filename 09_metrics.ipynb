{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f035e82c-14c2-4f4c-b177-4ba05bf416a6",
   "metadata": {},
   "source": [
    "# Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<polars.config.Config at 0x7543debf4560>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from adl.metrics import stratified_split\n",
    "\n",
    "pl.Config(tbl_rows=10, float_precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a94a22-f175-4c09-8988-9d8d07869932",
   "metadata": {},
   "source": [
    "**Note :** to use this notebook in Google Colab, create a new cell with\n",
    "the following lines and run it:\n",
    "\n",
    "```shell\n",
    "!git clone https://gitlab.in2p3.fr/jbarnier/ateliers_deep_learning.git\n",
    "%cd ateliers_deep_learning\n",
    "!pip install .\n",
    "```\n",
    "\n",
    "The train and validation losses allow to evaluate the evolution of the\n",
    "training process, but they are not necessarily good indicators to assess\n",
    "the quality of the network predictions. For this we need specific\n",
    "metrics aligned with the problem we are trying to solve.\n",
    "\n",
    "For example, for a regression problem we could compute the $R^2$ score,\n",
    "the mean absolute error or the mean absolute percentage error. For a\n",
    "classification problem we could use many different metrics such as\n",
    "accuracy, precision, recall, F1-score, ROC AUC, etc.\n",
    "\n",
    "## Computing metrics during training\n",
    "\n",
    "In this notebook we will use a dataset on [credit card fraud\n",
    "detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)\n",
    "downloaded from Kaggle and converted to a parquet file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (284_807, 30)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Class</th><th>Amount</th><th>V1</th><th>V2</th><th>V3</th><th>V4</th><th>V5</th><th>V6</th><th>V7</th><th>V8</th><th>V9</th><th>V10</th><th>V11</th><th>V12</th><th>V13</th><th>V14</th><th>V15</th><th>V16</th><th>V17</th><th>V18</th><th>V19</th><th>V20</th><th>V21</th><th>V22</th><th>V23</th><th>V24</th><th>V25</th><th>V26</th><th>V27</th><th>V28</th></tr><tr><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0</td><td>149.620</td><td>-1.360</td><td>-0.073</td><td>2.536</td><td>1.378</td><td>-0.338</td><td>0.462</td><td>0.240</td><td>0.099</td><td>0.364</td><td>0.091</td><td>-0.552</td><td>-0.618</td><td>-0.991</td><td>-0.311</td><td>1.468</td><td>-0.470</td><td>0.208</td><td>0.026</td><td>0.404</td><td>0.251</td><td>-0.018</td><td>0.278</td><td>-0.110</td><td>0.067</td><td>0.129</td><td>-0.189</td><td>0.134</td><td>-0.021</td></tr><tr><td>0</td><td>2.690</td><td>1.192</td><td>0.266</td><td>0.166</td><td>0.448</td><td>0.060</td><td>-0.082</td><td>-0.079</td><td>0.085</td><td>-0.255</td><td>-0.167</td><td>1.613</td><td>1.065</td><td>0.489</td><td>-0.144</td><td>0.636</td><td>0.464</td><td>-0.115</td><td>-0.183</td><td>-0.146</td><td>-0.069</td><td>-0.226</td><td>-0.639</td><td>0.101</td><td>-0.340</td><td>0.167</td><td>0.126</td><td>-0.009</td><td>0.015</td></tr><tr><td>0</td><td>378.660</td><td>-1.358</td><td>-1.340</td><td>1.773</td><td>0.380</td><td>-0.503</td><td>1.800</td><td>0.791</td><td>0.248</td><td>-1.515</td><td>0.208</td><td>0.625</td><td>0.066</td><td>0.717</td><td>-0.166</td><td>2.346</td><td>-2.890</td><td>1.110</td><td>-0.121</td><td>-2.262</td><td>0.525</td><td>0.248</td><td>0.772</td><td>0.909</td><td>-0.689</td><td>-0.328</td><td>-0.139</td><td>-0.055</td><td>-0.060</td></tr><tr><td>0</td><td>123.500</td><td>-0.966</td><td>-0.185</td><td>1.793</td><td>-0.863</td><td>-0.010</td><td>1.247</td><td>0.238</td><td>0.377</td><td>-1.387</td><td>-0.055</td><td>-0.226</td><td>0.178</td><td>0.508</td><td>-0.288</td><td>-0.631</td><td>-1.060</td><td>-0.684</td><td>1.966</td><td>-1.233</td><td>-0.208</td><td>-0.108</td><td>0.005</td><td>-0.190</td><td>-1.176</td><td>0.647</td><td>-0.222</td><td>0.063</td><td>0.061</td></tr><tr><td>0</td><td>69.990</td><td>-1.158</td><td>0.878</td><td>1.549</td><td>0.403</td><td>-0.407</td><td>0.096</td><td>0.593</td><td>-0.271</td><td>0.818</td><td>0.753</td><td>-0.823</td><td>0.538</td><td>1.346</td><td>-1.120</td><td>0.175</td><td>-0.451</td><td>-0.237</td><td>-0.038</td><td>0.803</td><td>0.409</td><td>-0.009</td><td>0.798</td><td>-0.137</td><td>0.141</td><td>-0.206</td><td>0.502</td><td>0.219</td><td>0.215</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>0</td><td>0.770</td><td>-11.881</td><td>10.072</td><td>-9.835</td><td>-2.067</td><td>-5.364</td><td>-2.607</td><td>-4.918</td><td>7.305</td><td>1.914</td><td>4.356</td><td>-1.593</td><td>2.712</td><td>-0.689</td><td>4.627</td><td>-0.924</td><td>1.108</td><td>1.992</td><td>0.511</td><td>-0.683</td><td>1.476</td><td>0.213</td><td>0.112</td><td>1.014</td><td>-0.509</td><td>1.437</td><td>0.250</td><td>0.944</td><td>0.824</td></tr><tr><td>0</td><td>24.790</td><td>-0.733</td><td>-0.055</td><td>2.035</td><td>-0.739</td><td>0.868</td><td>1.058</td><td>0.024</td><td>0.295</td><td>0.585</td><td>-0.976</td><td>-0.150</td><td>0.916</td><td>1.215</td><td>-0.675</td><td>1.165</td><td>-0.712</td><td>-0.026</td><td>-1.221</td><td>-1.546</td><td>0.060</td><td>0.214</td><td>0.924</td><td>0.012</td><td>-1.016</td><td>-0.607</td><td>-0.395</td><td>0.068</td><td>-0.054</td></tr><tr><td>0</td><td>67.880</td><td>1.920</td><td>-0.301</td><td>-3.250</td><td>-0.558</td><td>2.631</td><td>3.031</td><td>-0.297</td><td>0.708</td><td>0.432</td><td>-0.485</td><td>0.412</td><td>0.063</td><td>-0.184</td><td>-0.511</td><td>1.329</td><td>0.141</td><td>0.314</td><td>0.396</td><td>-0.577</td><td>0.001</td><td>0.232</td><td>0.578</td><td>-0.038</td><td>0.640</td><td>0.266</td><td>-0.087</td><td>0.004</td><td>-0.027</td></tr><tr><td>0</td><td>10.000</td><td>-0.240</td><td>0.530</td><td>0.703</td><td>0.690</td><td>-0.378</td><td>0.624</td><td>-0.686</td><td>0.679</td><td>0.392</td><td>-0.399</td><td>-1.934</td><td>-0.963</td><td>-1.042</td><td>0.450</td><td>1.963</td><td>-0.609</td><td>0.510</td><td>1.114</td><td>2.898</td><td>0.127</td><td>0.265</td><td>0.800</td><td>-0.163</td><td>0.123</td><td>-0.569</td><td>0.547</td><td>0.109</td><td>0.105</td></tr><tr><td>0</td><td>217.000</td><td>-0.533</td><td>-0.190</td><td>0.703</td><td>-0.506</td><td>-0.013</td><td>-0.650</td><td>1.577</td><td>-0.415</td><td>0.486</td><td>-0.915</td><td>-1.040</td><td>-0.032</td><td>-0.188</td><td>-0.084</td><td>0.041</td><td>-0.303</td><td>-0.660</td><td>0.167</td><td>-0.256</td><td>0.383</td><td>0.261</td><td>0.643</td><td>0.377</td><td>0.009</td><td>-0.474</td><td>-0.818</td><td>-0.002</td><td>0.014</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (284_807, 30)\n",
       "┌───────┬─────────┬─────────┬────────┬───┬────────┬────────┬────────┬────────┐\n",
       "│ Class ┆ Amount  ┆ V1      ┆ V2     ┆ … ┆ V25    ┆ V26    ┆ V27    ┆ V28    │\n",
       "│ ---   ┆ ---     ┆ ---     ┆ ---    ┆   ┆ ---    ┆ ---    ┆ ---    ┆ ---    │\n",
       "│ i64   ┆ f64     ┆ f64     ┆ f64    ┆   ┆ f64    ┆ f64    ┆ f64    ┆ f64    │\n",
       "╞═══════╪═════════╪═════════╪════════╪═══╪════════╪════════╪════════╪════════╡\n",
       "│ 0     ┆ 149.620 ┆ -1.360  ┆ -0.073 ┆ … ┆ 0.129  ┆ -0.189 ┆ 0.134  ┆ -0.021 │\n",
       "│ 0     ┆ 2.690   ┆ 1.192   ┆ 0.266  ┆ … ┆ 0.167  ┆ 0.126  ┆ -0.009 ┆ 0.015  │\n",
       "│ 0     ┆ 378.660 ┆ -1.358  ┆ -1.340 ┆ … ┆ -0.328 ┆ -0.139 ┆ -0.055 ┆ -0.060 │\n",
       "│ 0     ┆ 123.500 ┆ -0.966  ┆ -0.185 ┆ … ┆ 0.647  ┆ -0.222 ┆ 0.063  ┆ 0.061  │\n",
       "│ 0     ┆ 69.990  ┆ -1.158  ┆ 0.878  ┆ … ┆ -0.206 ┆ 0.502  ┆ 0.219  ┆ 0.215  │\n",
       "│ …     ┆ …       ┆ …       ┆ …      ┆ … ┆ …      ┆ …      ┆ …      ┆ …      │\n",
       "│ 0     ┆ 0.770   ┆ -11.881 ┆ 10.072 ┆ … ┆ 1.437  ┆ 0.250  ┆ 0.944  ┆ 0.824  │\n",
       "│ 0     ┆ 24.790  ┆ -0.733  ┆ -0.055 ┆ … ┆ -0.607 ┆ -0.395 ┆ 0.068  ┆ -0.054 │\n",
       "│ 0     ┆ 67.880  ┆ 1.920   ┆ -0.301 ┆ … ┆ 0.266  ┆ -0.087 ┆ 0.004  ┆ -0.027 │\n",
       "│ 0     ┆ 10.000  ┆ -0.240  ┆ 0.530  ┆ … ┆ -0.569 ┆ 0.547  ┆ 0.109  ┆ 0.105  │\n",
       "│ 0     ┆ 217.000 ┆ -0.533  ┆ -0.190 ┆ … ┆ -0.474 ┆ -0.818 ┆ -0.002 ┆ 0.014  │\n",
       "└───────┴─────────┴─────────┴────────┴───┴────────┴────────┴────────┴────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pl.read_parquet(\"data/creditcard.parquet\")\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d2b4cd-8b11-43d7-a1d4-c3b328df74f9",
   "metadata": {},
   "source": [
    "This tabular dataset contains 284 807 rows describing credit card\n",
    "transactions which happened in september 2013 in Europe:\n",
    "\n",
    "-   The `Amount` column is the transaction amount\n",
    "-   The columns `V1` to `V28` are different characteristics of the\n",
    "    transaction anonymized through a PCA transformation\n",
    "-   The `Class` column has value 1 if the transaction is a credit card\n",
    "    fraud, and 0 otherwise\n",
    "\n",
    "The dataset is highly unbalanced, as there are only 492 fraudulent\n",
    "transactions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Class</th><th>count</th></tr><tr><td>i64</td><td>u32</td></tr></thead><tbody><tr><td>1</td><td>492</td></tr><tr><td>0</td><td>284315</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 2)\n",
       "┌───────┬────────┐\n",
       "│ Class ┆ count  │\n",
       "│ ---   ┆ ---    │\n",
       "│ i64   ┆ u32    │\n",
       "╞═══════╪════════╡\n",
       "│ 1     ┆ 492    │\n",
       "│ 0     ┆ 284315 │\n",
       "└───────┴────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.get_column(\"Class\").value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed1d49a-f094-48d2-82c3-5a3002401cfa",
   "metadata": {},
   "source": [
    "We split this dataset into training and validation data using stratified\n",
    "sampling to maintain the same proportion of fraudulent transactions in\n",
    "both datasets. It is necessary because if we sampled randomly we could\n",
    "get very few of them in the validation set due to their low prevalence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = stratified_split(d, valid_proportion=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c95d0a-8e03-4c10-9e9c-54265c81a11d",
   "metadata": {},
   "source": [
    "Finally we create a small feed forward neural network and a training\n",
    "step function as seen previously.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FraudDetectionNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(29, 10), nn.ReLU(), nn.Linear(10, 10), nn.ReLU(), nn.Linear(10, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).squeeze()\n",
    "\n",
    "\n",
    "def train_step(epoch, model, loss_fn, optimizer):\n",
    "    # Run training step\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(X_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # Run validation step\n",
    "    model.eval()\n",
    "    y_valid_pred = model(X_valid)\n",
    "    valid_loss = loss_fn(y_valid_pred, y_valid)\n",
    "    print(f\"Epoch: {epoch + 1:2}, loss: {loss:5.3f}, valid_loss: {valid_loss:5.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a65c17-d61f-461d-a9ca-01898123b4d3",
   "metadata": {},
   "source": [
    "We launch a training process using a cross entropy loss, which is more\n",
    "suitable for a classification problem such as this one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1, loss: 0.649, valid_loss: 0.580\n",
      "Epoch:  2, loss: 0.580, valid_loss: 0.518\n",
      "Epoch:  3, loss: 0.517, valid_loss: 0.460\n",
      "Epoch:  4, loss: 0.460, valid_loss: 0.408\n",
      "Epoch:  5, loss: 0.408, valid_loss: 0.359\n",
      "Epoch:  6, loss: 0.359, valid_loss: 0.313\n",
      "Epoch:  7, loss: 0.314, valid_loss: 0.271\n",
      "Epoch:  8, loss: 0.272, valid_loss: 0.232\n",
      "Epoch:  9, loss: 0.234, valid_loss: 0.196\n",
      "Epoch: 10, loss: 0.198, valid_loss: 0.164\n",
      "Epoch: 11, loss: 0.166, valid_loss: 0.135\n",
      "Epoch: 12, loss: 0.138, valid_loss: 0.112\n",
      "Epoch: 13, loss: 0.116, valid_loss: 0.095\n",
      "Epoch: 14, loss: 0.099, valid_loss: 0.083\n",
      "Epoch: 15, loss: 0.088, valid_loss: 0.074\n",
      "Epoch: 16, loss: 0.081, valid_loss: 0.070\n",
      "Epoch: 17, loss: 0.077, valid_loss: 0.067\n",
      "Epoch: 18, loss: 0.075, valid_loss: 0.065\n",
      "Epoch: 19, loss: 0.074, valid_loss: 0.062\n",
      "Epoch: 20, loss: 0.072, valid_loss: 0.059\n"
     ]
    }
   ],
   "source": [
    "model = FraudDetectionNetwork()\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.01)\n",
    "\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    train_step(epoch, model, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfd9ad1-d99d-4349-8929-db15efb16657",
   "metadata": {},
   "source": [
    "The training process seems to go well, both the training and validation\n",
    "losses seem to go down regularly.\n",
    "\n",
    "Let’s take a closer look at the predictions of our model on the\n",
    "validation data. When applying `model` to `X_valid`, we can see that the\n",
    "result for each observation is a set of two numbers. The first one is\n",
    "associated to `Class=0`, and the second one to `Class=1`. These values\n",
    "are not probabilities as they are not numbers between 0 and 1: they are\n",
    "called _logits_.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.2758, -4.3871],\n",
       "        [ 4.0309, -3.6199],\n",
       "        [12.1061, -9.2236],\n",
       "        ...,\n",
       "        [ 5.9372, -5.2991],\n",
       "        [ 4.5024, -4.0959],\n",
       "        [10.4529, -8.6524]], grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = model(X_valid)\n",
    "logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72548e45-e0a1-406b-bef5-8ab73fd948ce",
   "metadata": {},
   "source": [
    "Logits can be converted into probabilites by applying a _softmax_\n",
    "function to them. But we can also determine the class of each validation\n",
    "data point by applying `torch.argmax` along the second dimension of our\n",
    "logits: this will return `0` if the logit associated to `Class=0` is\n",
    "higher, and `1` otherwise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = torch.argmax(logits, dim=1)\n",
    "classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70584e95-4bbc-4503-8066-6daab9438cc5",
   "metadata": {},
   "source": [
    "So now we can finally look at the number of fraudulent transactions\n",
    "predicted by our model on our validation dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(classes == 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d465eb4-4a62-4e9a-a6ed-73aeed73ea69",
   "metadata": {},
   "source": [
    "And this value is 0… So our network is learning, as the cross entropy\n",
    "loss between our logits and the target values is going down, but for the\n",
    "moment its results are useless.\n",
    "\n",
    "So if the loss value is useful to assess the progress of our training\n",
    "process, it is not necessarily a good indicator of the quality of its\n",
    "results. To evaluate this we need to use other metrics, which will\n",
    "depend on the problem we want to solve.\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "One very simple metric we just computed is the number of fraudulent\n",
    "transactions identified by the model on the validation dataset. It could\n",
    "be useful to add this metric to our training process output.\n",
    "\n",
    "Modify the `train_step` function above to create a new\n",
    "`train_step_nfraud` method which computes and displays, for each epoch,\n",
    "the train loss, the validation loss, and the number of predicted\n",
    "fraudulent transactions in the validation dataset.\n",
    "\n",
    "Run this new training process for 10 epochs on a new\n",
    "`FraudDetectionNetwork` model.\n",
    "\n",
    "We can see that at the start of our training process the model predicts\n",
    "some fraudulent transactions, but this number goes down to 0 rapidly.\n",
    "\n",
    "There are many other metrics we can use to assess the results of a\n",
    "classification problem, and several Python packages provide methods to\n",
    "compute them more easily. For example, we could use the\n",
    "`precision_score` and `recall_score` methods of the `scikit-learn`\n",
    "package to compute precision and recall at each epoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cell-23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1, loss: 2.695, valid_loss: 2.271, n_fraud: 56962, precision: 0.002, recall: 1.000\n",
      "Epoch:   2, loss: 2.254, valid_loss: 1.896, n_fraud: 56962, precision: 0.002, recall: 1.000\n",
      "Epoch:   3, loss: 1.882, valid_loss: 1.570, n_fraud: 56888, precision: 0.002, recall: 1.000\n",
      "Epoch:   4, loss: 1.559, valid_loss: 1.262, n_fraud: 56370, precision: 0.002, recall: 1.000\n",
      "Epoch:   5, loss: 1.255, valid_loss: 0.943, n_fraud: 54516, precision: 0.002, recall: 0.949\n",
      "Epoch:   6, loss: 0.940, valid_loss: 0.681, n_fraud: 33772, precision: 0.001, recall: 0.378\n",
      "Epoch:   7, loss: 0.681, valid_loss: 0.564, n_fraud: 6206, precision: 0.000, recall: 0.020\n",
      "Epoch:   8, loss: 0.563, valid_loss: 0.492, n_fraud:   1, precision: 0.000, recall: 0.000\n",
      "Epoch:   9, loss: 0.492, valid_loss: 0.440, n_fraud:   0, precision: 0.000, recall: 0.000\n",
      "Epoch:  10, loss: 0.440, valid_loss: 0.396, n_fraud:   0, precision: 0.000, recall: 0.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "\n",
    "def train_step_metrics(epoch, model, loss_fn, optimizer):\n",
    "    # Run training step\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(X_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Run validation step\n",
    "    y_valid_pred = model(X_valid)\n",
    "    valid_loss = loss_fn(y_valid_pred, y_valid)\n",
    "\n",
    "    # Compute metrics\n",
    "    pred_classes = torch.argmax(y_valid_pred.detach(), dim=1)\n",
    "    n_fraud = torch.sum(pred_classes == 1)\n",
    "    precision = precision_score(y_valid, pred_classes) if n_fraud > 0 else 0\n",
    "    recall = recall_score(y_valid, pred_classes) if n_fraud > 0 else 0\n",
    "    print(\n",
    "        f\"Epoch: {epoch + 1:3}, loss: {loss:5.3f}, valid_loss: {valid_loss:5.3f}, n_fraud: {n_fraud:3}, \"\n",
    "        f\"precision: {precision:5.3f}, recall: {recall:5.3f}\"\n",
    "    )\n",
    "\n",
    "\n",
    "model = FraudDetectionNetwork()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.01)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    train_step_metrics(epoch, model, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c705443-4dc2-4c86-8262-88053f8719d5",
   "metadata": {},
   "source": [
    "So, the metrics are not good, but the loss is still going down. Maybe we\n",
    "can look at what happens if we run the training process for longer?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cell-25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1, loss: 0.837, valid_loss: 0.421, n_fraud: 329, precision: 0.088, recall: 0.296\n",
      "Epoch:   2, loss: 0.420, valid_loss: 0.344, n_fraud:  85, precision: 0.153, recall: 0.133\n",
      "Epoch:   3, loss: 0.344, valid_loss: 0.302, n_fraud:  20, precision: 0.300, recall: 0.061\n",
      "Epoch:   4, loss: 0.302, valid_loss: 0.273, n_fraud:   3, precision: 0.000, recall: 0.000\n",
      "Epoch:   5, loss: 0.274, valid_loss: 0.250, n_fraud:   0, precision: 0.000, recall: 0.000\n",
      "Epoch:   6, loss: 0.251, valid_loss: 0.231, n_fraud:   0, precision: 0.000, recall: 0.000\n",
      "Epoch:   7, loss: 0.232, valid_loss: 0.214, n_fraud:   0, precision: 0.000, recall: 0.000\n",
      "Epoch:   8, loss: 0.216, valid_loss: 0.199, n_fraud:   0, precision: 0.000, recall: 0.000\n",
      "Epoch:   9, loss: 0.201, valid_loss: 0.186, n_fraud:   0, precision: 0.000, recall: 0.000\n",
      "Epoch:  10, loss: 0.187, valid_loss: 0.173, n_fraud:   0, precision: 0.000, recall: 0.000\n",
      "Epoch:  11, loss: 0.175, valid_loss: 0.160, n_fraud:   0, precision: 0.000, recall: 0.000\n",
      "Epoch:  12, loss: 0.162, valid_loss: 0.148, n_fraud:   0, precision: 0.000, recall: 0.000\n",
      "Epoch:  13, loss: 0.151, valid_loss: 0.137, n_fraud:   0, precision: 0.000, recall: 0.000\n",
      "Epoch:  14, loss: 0.139, valid_loss: 0.125, n_fraud:   0, precision: 0.000, recall: 0.000\n",
      "Epoch:  15, loss: 0.128, valid_loss: 0.114, n_fraud:   0, precision: 0.000, recall: 0.000\n",
      "Epoch:  16, loss: 0.117, valid_loss: 0.104, n_fraud:   0, precision: 0.000, recall: 0.000\n",
      "Epoch:  17, loss: 0.107, valid_loss: 0.094, n_fraud:   0, precision: 0.000, recall: 0.000\n",
      "Epoch:  18, loss: 0.097, valid_loss: 0.085, n_fraud:   0, precision: 0.000, recall: 0.000\n",
      "Epoch:  19, loss: 0.089, valid_loss: 0.077, n_fraud:   0, precision: 0.000, recall: 0.000\n",
      "Epoch:  20, loss: 0.082, valid_loss: 0.072, n_fraud:   0, precision: 0.000, recall: 0.000\n",
      "Epoch:  21, loss: 0.077, valid_loss: 0.067, n_fraud:   0, precision: 0.000, recall: 0.000\n",
      "Epoch:  22, loss: 0.073, valid_loss: 0.063, n_fraud:   0, precision: 0.000, recall: 0.000\n",
      "Epoch:  23, loss: 0.070, valid_loss: 0.060, n_fraud:   0, precision: 0.000, recall: 0.000\n",
      "Epoch:  24, loss: 0.067, valid_loss: 0.057, n_fraud:   0, precision: 0.000, recall: 0.000\n",
      "Epoch:  25, loss: 0.064, valid_loss: 0.054, n_fraud:   0, precision: 0.000, recall: 0.000\n",
      "Epoch:  26, loss: 0.061, valid_loss: 0.050, n_fraud:   0, precision: 0.000, recall: 0.000\n",
      "Epoch:  27, loss: 0.058, valid_loss: 0.047, n_fraud:   0, precision: 0.000, recall: 0.000\n",
      "Epoch:  28, loss: 0.054, valid_loss: 0.044, n_fraud:   0, precision: 0.000, recall: 0.000\n",
      "Epoch:  29, loss: 0.051, valid_loss: 0.042, n_fraud:   0, precision: 0.000, recall: 0.000\n",
      "Epoch:  30, loss: 0.049, valid_loss: 0.040, n_fraud:   0, precision: 0.000, recall: 0.000\n",
      "Epoch:  31, loss: 0.047, valid_loss: 0.038, n_fraud:   0, precision: 0.000, recall: 0.000\n",
      "Epoch:  32, loss: 0.045, valid_loss: 0.037, n_fraud:   0, precision: 0.000, recall: 0.000\n",
      "Epoch:  33, loss: 0.043, valid_loss: 0.036, n_fraud:   0, precision: 0.000, recall: 0.000\n",
      "Epoch:  34, loss: 0.042, valid_loss: 0.035, n_fraud:   0, precision: 0.000, recall: 0.000\n",
      "Epoch:  35, loss: 0.041, valid_loss: 0.034, n_fraud:   0, precision: 0.000, recall: 0.000\n",
      "Epoch:  36, loss: 0.040, valid_loss: 0.033, n_fraud:   0, precision: 0.000, recall: 0.000\n",
      "Epoch:  37, loss: 0.039, valid_loss: 0.032, n_fraud:   0, precision: 0.000, recall: 0.000\n",
      "Epoch:  38, loss: 0.038, valid_loss: 0.031, n_fraud:   0, precision: 0.000, recall: 0.000\n",
      "Epoch:  39, loss: 0.037, valid_loss: 0.030, n_fraud:   0, precision: 0.000, recall: 0.000\n",
      "Epoch:  40, loss: 0.036, valid_loss: 0.029, n_fraud:   0, precision: 0.000, recall: 0.000\n",
      "Epoch:  41, loss: 0.034, valid_loss: 0.028, n_fraud:   0, precision: 0.000, recall: 0.000\n",
      "Epoch:  42, loss: 0.033, valid_loss: 0.027, n_fraud:   0, precision: 0.000, recall: 0.000\n",
      "Epoch:  43, loss: 0.032, valid_loss: 0.026, n_fraud:   0, precision: 0.000, recall: 0.000\n",
      "Epoch:  44, loss: 0.031, valid_loss: 0.025, n_fraud:   0, precision: 0.000, recall: 0.000\n",
      "Epoch:  45, loss: 0.031, valid_loss: 0.024, n_fraud:   0, precision: 0.000, recall: 0.000\n",
      "Epoch:  46, loss: 0.030, valid_loss: 0.024, n_fraud:   0, precision: 0.000, recall: 0.000\n",
      "Epoch:  47, loss: 0.030, valid_loss: 0.023, n_fraud:   9, precision: 1.000, recall: 0.092\n",
      "Epoch:  48, loss: 0.029, valid_loss: 0.023, n_fraud:  14, precision: 0.786, recall: 0.112\n",
      "Epoch:  49, loss: 0.029, valid_loss: 0.022, n_fraud:  24, precision: 0.667, recall: 0.163\n",
      "Epoch:  50, loss: 0.028, valid_loss: 0.022, n_fraud:  36, precision: 0.778, recall: 0.286\n",
      "Epoch:  51, loss: 0.027, valid_loss: 0.021, n_fraud:  43, precision: 0.791, recall: 0.347\n",
      "Epoch:  52, loss: 0.027, valid_loss: 0.021, n_fraud:  53, precision: 0.755, recall: 0.408\n",
      "Epoch:  53, loss: 0.026, valid_loss: 0.021, n_fraud:  61, precision: 0.754, recall: 0.469\n",
      "Epoch:  54, loss: 0.026, valid_loss: 0.020, n_fraud:  71, precision: 0.761, recall: 0.551\n",
      "Epoch:  55, loss: 0.025, valid_loss: 0.020, n_fraud:  75, precision: 0.773, recall: 0.592\n",
      "Epoch:  56, loss: 0.025, valid_loss: 0.020, n_fraud:  79, precision: 0.772, recall: 0.622\n",
      "Epoch:  57, loss: 0.025, valid_loss: 0.019, n_fraud:  79, precision: 0.772, recall: 0.622\n",
      "Epoch:  58, loss: 0.024, valid_loss: 0.019, n_fraud:  80, precision: 0.762, recall: 0.622\n",
      "Epoch:  59, loss: 0.024, valid_loss: 0.018, n_fraud:  81, precision: 0.765, recall: 0.633\n",
      "Epoch:  60, loss: 0.023, valid_loss: 0.018, n_fraud:  83, precision: 0.759, recall: 0.643\n",
      "Epoch:  61, loss: 0.023, valid_loss: 0.018, n_fraud:  84, precision: 0.750, recall: 0.643\n",
      "Epoch:  62, loss: 0.023, valid_loss: 0.017, n_fraud:  85, precision: 0.753, recall: 0.653\n",
      "Epoch:  63, loss: 0.022, valid_loss: 0.017, n_fraud:  85, precision: 0.753, recall: 0.653\n",
      "Epoch:  64, loss: 0.022, valid_loss: 0.017, n_fraud:  86, precision: 0.756, recall: 0.663\n",
      "Epoch:  65, loss: 0.021, valid_loss: 0.016, n_fraud:  86, precision: 0.756, recall: 0.663\n",
      "Epoch:  66, loss: 0.021, valid_loss: 0.015, n_fraud:  86, precision: 0.756, recall: 0.663\n",
      "Epoch:  67, loss: 0.020, valid_loss: 0.015, n_fraud:  86, precision: 0.756, recall: 0.663\n",
      "Epoch:  68, loss: 0.019, valid_loss: 0.014, n_fraud:  88, precision: 0.761, recall: 0.684\n",
      "Epoch:  69, loss: 0.018, valid_loss: 0.013, n_fraud:  89, precision: 0.764, recall: 0.694\n",
      "Epoch:  70, loss: 0.017, valid_loss: 0.013, n_fraud:  90, precision: 0.767, recall: 0.704\n",
      "Epoch:  71, loss: 0.016, valid_loss: 0.012, n_fraud:  90, precision: 0.767, recall: 0.704\n",
      "Epoch:  72, loss: 0.014, valid_loss: 0.011, n_fraud:  90, precision: 0.767, recall: 0.704\n",
      "Epoch:  73, loss: 0.013, valid_loss: 0.010, n_fraud:  91, precision: 0.769, recall: 0.714\n",
      "Epoch:  74, loss: 0.012, valid_loss: 0.009, n_fraud:  93, precision: 0.763, recall: 0.724\n",
      "Epoch:  75, loss: 0.010, valid_loss: 0.009, n_fraud:  94, precision: 0.766, recall: 0.735\n",
      "Epoch:  76, loss: 0.009, valid_loss: 0.009, n_fraud:  96, precision: 0.771, recall: 0.755\n",
      "Epoch:  77, loss: 0.008, valid_loss: 0.008, n_fraud:  97, precision: 0.773, recall: 0.765\n",
      "Epoch:  78, loss: 0.008, valid_loss: 0.008, n_fraud:  97, precision: 0.773, recall: 0.765\n",
      "Epoch:  79, loss: 0.007, valid_loss: 0.008, n_fraud:  97, precision: 0.773, recall: 0.765\n",
      "Epoch:  80, loss: 0.007, valid_loss: 0.007, n_fraud:  99, precision: 0.778, recall: 0.786\n",
      "Epoch:  81, loss: 0.006, valid_loss: 0.007, n_fraud: 100, precision: 0.770, recall: 0.786\n",
      "Epoch:  82, loss: 0.006, valid_loss: 0.006, n_fraud:  98, precision: 0.786, recall: 0.786\n",
      "Epoch:  83, loss: 0.005, valid_loss: 0.006, n_fraud:  97, precision: 0.794, recall: 0.786\n",
      "Epoch:  84, loss: 0.006, valid_loss: 0.005, n_fraud:  97, precision: 0.794, recall: 0.786\n",
      "Epoch:  85, loss: 0.005, valid_loss: 0.005, n_fraud:  99, precision: 0.788, recall: 0.796\n"
     ]
    }
   ],
   "source": [
    "model = FraudDetectionNetwork()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.01)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "epochs = 85\n",
    "for epoch in range(epochs):\n",
    "    train_step_metrics(epoch, model, loss_fn, optimizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c364baa2-4e0d-44b6-9dbc-bb654eca2e17",
   "metadata": {},
   "source": [
    "Now we can see that after about 50 epochs, our model starts to predict\n",
    "fraudulent transactions again, with growing values of precision and\n",
    "recall. At epoch 85 we get a precision of 0.79 and a recall of 0.80.\n",
    "\n",
    "## Computing metrics after training\n",
    "\n",
    "Metrics are useful during training, but they are also very important\n",
    "post-training, to more accurately assess the results.\n",
    "\n",
    "For example, we can compute the _confusion matrix_ of our trained model\n",
    "on our validation dataset by using scikit-learn’s `confusion_matrix`\n",
    "method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cell-28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[56843,    21],\n",
       "       [   20,    78]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "preds = model(X_valid)\n",
    "preds = torch.argmax(preds, dim=1)\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_valid, preds)\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1b00e0-32bc-41c9-987c-6817b747eee4",
   "metadata": {},
   "source": [
    "Better yet, we can use `ConfusionMatrixDisplay` to generate a much more\n",
    "readable plot of the confusion matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cell-30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x75438f263aa0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f7a5eb-cc04-489b-ac9c-745738a65c09",
   "metadata": {},
   "source": [
    "## Computing metrics when using mini-batches\n",
    "\n",
    "### Mini-batches training process\n",
    "\n",
    "Suppose that we are now using mini-batches during our training process,\n",
    "as seen in the previous notebook: instead of feeding all training or\n",
    "validation data at once during each training step, we’ll use smaller\n",
    "subsets of data.\n",
    "\n",
    "To do this, we first create a `FraudDataset` class and corresponding\n",
    "`DataLoader` instances for training and validation data, with a batch\n",
    "size of 256.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cell-32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FraudDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.y = y\n",
    "        self.x = x\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "\n",
    "\n",
    "train_dataset = FraudDataset(x=X_train, y=y_train)\n",
    "valid_dataset = FraudDataset(x=X_valid, y=y_valid)\n",
    "\n",
    "batch_size = 256\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    valid_dataset, batch_size=batch_size, shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57913349-a138-4c16-8485-4ebdbb045a56",
   "metadata": {},
   "source": [
    "We then define two functions:\n",
    "\n",
    "-   `train_step` will run a training epoch, _ie_ apply a training step\n",
    "    to each mini-batches in the training data loader\n",
    "-   `eval_step` will run a validation epoch, _ie_ apply an evaluation\n",
    "    step to each mini-batches in the validation data loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cell-34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, loss_fn, optimizer):\n",
    "    # Switch model into train mode\n",
    "    model.train()\n",
    "    loss = 0\n",
    "    for input, target in train_loader:\n",
    "        # Apply training step to batch\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(input)\n",
    "        batch_loss = loss_fn(pred, target)\n",
    "        loss += batch_loss\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "    # Compute and return the mean loss for this epoch\n",
    "    loss /= len(train_loader)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def eval_step(model, loss_fn):\n",
    "    # Switch model into eval mode\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    for input, target in valid_loader:\n",
    "        # Apply evaluation step to batch\n",
    "        pred = model(input)\n",
    "        batch_loss = loss_fn(pred, target)\n",
    "        loss += batch_loss\n",
    "    # Compute and return the mean loss for this epoch\n",
    "    loss /= len(valid_loader)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64c6db5-3936-419b-94af-c2f4c61909bf",
   "metadata": {},
   "source": [
    "We can now run our training process on a few epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cell-36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1, loss: 0.020, valid_loss: 0.004\n",
      "Epoch:   2, loss: 0.005, valid_loss: 0.004\n",
      "Epoch:   3, loss: 0.004, valid_loss: 0.004\n",
      "Epoch:   4, loss: 0.004, valid_loss: 0.004\n",
      "Epoch:   5, loss: 0.004, valid_loss: 0.004\n"
     ]
    }
   ],
   "source": [
    "model = FraudDetectionNetwork()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.01)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 5\n",
    "torch.manual_seed(42)\n",
    "for epoch in range(epochs):\n",
    "    loss = train_step(model, loss_fn, optimizer)\n",
    "    valid_loss = eval_step(model, loss_fn)\n",
    "    print(f\"Epoch: {epoch + 1:3}, loss: {loss:5.3f}, valid_loss: {valid_loss:5.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe535024-6d44-4584-8d0b-1821d4beef19",
   "metadata": {},
   "source": [
    "### Computing a single metric\n",
    "\n",
    "To add metric computation during this training process with\n",
    "mini-batches, we can calculate the metric value for each batch. However,\n",
    "obtaining the overall epoch metric value for the entire validation data\n",
    "from these mini-batch values can be challenging. Libraries like\n",
    "`scikit-learn` do not provide methods out of the box to do this, and\n",
    "manual implementation can be complicated and prone to errors.\n",
    "\n",
    "A way to do it is to use the `torchmetrics` python package. This package\n",
    "provides a great number of metrics which can be used directly on a whole\n",
    "dataset, but can also be applied to mini-batches the following way:\n",
    "\n",
    "1.  first, we instantiate a metric object from one of `torchmetrics`\n",
    "    methods. For example, we can use the `BinaryF1Score` class to create\n",
    "    a `f1_metric` object with `f1_metric = BinaryF1Score()`\n",
    "2.  at the start of each epoch, we reset the metric with\n",
    "    `f1_metric.reset()`\n",
    "3.  for each mini-batch, we update the metric using the mini-batch\n",
    "    predictions and targets with the `update()` method\n",
    "4.  finally, at the end of the epoch, we can compute the overall epoch\n",
    "    metric value using `f1_metric.compute()`\n",
    "\n",
    "Here is how we can include an F1 metric computation in our evaluation\n",
    "step by creating a new `eval_step_f1` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cell-38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.classification import BinaryF1Score\n",
    "\n",
    "# Instantiate F1 score metric object\n",
    "f1_metric = BinaryF1Score()\n",
    "\n",
    "\n",
    "def eval_step_f1(model, loss_fn):\n",
    "    # Switch model into eval mode\n",
    "    model.eval()\n",
    "    # Reset F1 score\n",
    "    f1_metric.reset()\n",
    "    loss = 0\n",
    "\n",
    "    for input, target in valid_loader:\n",
    "        # Apply evaluation step to batch\n",
    "        pred = model(input)\n",
    "        batch_loss = loss_fn(pred, target)\n",
    "        loss += batch_loss\n",
    "        # Update metric\n",
    "        classes_pred = torch.argmax(pred, dim=1)\n",
    "        f1_metric.update(classes_pred, target)\n",
    "\n",
    "    # Compute overall loss and metric\n",
    "    loss /= len(valid_loader)\n",
    "    f1_score = f1_metric.compute()\n",
    "\n",
    "    return loss, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cell-39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1, loss: 0.019, valid_loss: 0.004, f1: 0.772\n",
      "Epoch:   2, loss: 0.005, valid_loss: 0.005, f1: 0.671\n",
      "Epoch:   3, loss: 0.004, valid_loss: 0.003, f1: 0.819\n",
      "Epoch:   4, loss: 0.004, valid_loss: 0.004, f1: 0.802\n",
      "Epoch:   5, loss: 0.005, valid_loss: 0.004, f1: 0.000\n"
     ]
    }
   ],
   "source": [
    "model = FraudDetectionNetwork()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.01)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "epochs = 5\n",
    "torch.manual_seed(42)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss = train_step(model, loss_fn, optimizer)\n",
    "    valid_loss, valid_f1 = eval_step_f1(model, loss_fn)\n",
    "    print(\n",
    "        f\"Epoch: {epoch + 1:3}, loss: {loss:5.3f}, valid_loss: {valid_loss:5.3f}, f1: {valid_f1:5.3f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db0bc71-0541-4543-9611-a61b9f123683",
   "metadata": {},
   "source": [
    "Creating a separate evaluation step function is interesting because it\n",
    "makes it easy to apply a trained model to a dataset using mini-batches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cell-41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0044, grad_fn=<DivBackward0>), tensor(0.))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_step_f1(model, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c33100-2f0d-45aa-babb-f496a412700c",
   "metadata": {},
   "source": [
    "### Computing a list of metrics\n",
    "\n",
    "In general we want to compute not just one but multiple metrics. For\n",
    "instance, we might want to compute the F1-score, precision and recall\n",
    "values for our classification problem.\n",
    "\n",
    "`torchmetrics` provides a `MetricCollection` class which allows to do\n",
    "that quite easily. By passing a list of metrics to `MetricCollection`,\n",
    "we can create a collection object which will have the same `reset()`,\n",
    "`update()` and `compute()` methods as single metrics. When used, these\n",
    "methods will be called for all the metrics in the list.\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "Create the following metrics collection object:\n",
    "\n",
    "```py\n",
    "from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall\n",
    "from torchmetrics import MetricCollection\n",
    "\n",
    "metrics_list = MetricCollection(\n",
    "    [\n",
    "        BinaryPrecision(),\n",
    "        BinaryRecall(),\n",
    "        BinaryF1Score(),\n",
    "    ]\n",
    ")\n",
    "```\n",
    "\n",
    "Create a new `eval_step_metrics` function that add these metrics\n",
    "computation to the evaluation step of our training process and display\n",
    "their values at the end of each epoch. Run this training process for 10\n",
    "epochs.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
